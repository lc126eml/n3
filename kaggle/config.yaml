id: xulijuan
desc: b
desc_keys: ["lr"]
run_id: 0
total_runs: 8
seed: 42
simple:
  - max_epochs: 130
  - break_at: 30
  - accum_steps: 4
  - checkpoint.resume_config_skip_keys: []
  - data.data_module.train_config.batch_size: 40
  - data.data_module.train_config.debug_enumerate_batches: true
  # - optim.warmup_epochs: 2
  - optim.warmup_batch_cost_discount: 0.55
  # - data.data_module.train_config.num_workers: 4
  # - data.data_module.train_config.resolution: "[(160,128),(240, 224),(240, 240), (384, 224), (384, 336), (384, 384), (400, 384), (400, 400), (416, 400), (416, 416), (432, 416), (432, 432)]"
  - lr: 1.0e-4
  - mode: train
  - resume_bs: true
  - total_run_time_hr: 12.0
# simple:
#   - data.data_module.train_config.datasets.0: "HyperSim_Multi(allow_repeat=False, split='train', ROOT=['${data.data_root}/hypersim_processed'], image_list_path='/kaggle/working', transform=None, resolution=${..resolution}, num_views=${..num_views}, samples_per_scene=6, max_interval=25, min_interval=1, augs=${..augs})"
# simple:
#   - logging.log_freq: 100
#   - break_at: 20

is_private: false
enable_gpu: true
enable_tpu: false
enable_internet: true
resume_full_ckpt: false
resume_source: null
resume_infer: false

# Optional: exact dataset/kernel dependencies for Kaggle metadata
dataset_sources:
kernel_sources: []
competition_sources: []
model_sources: []
