optimized_metric: val/loss
task_name: train
tags:
- dev
train: true
test: true
ckpt_path: null
seed: 66
data:
  data_root: /lc/data/3D
  num_views: 5
  num_views_val: 5
  data_module:
    _target_: src.dust3r.datasets.base.multiview_dust3r_datamodule.MultiViewDUSt3RDataModule
    train_datasets:
    - HyperSim_Multi(allow_repeat=False, split='train', ROOT='${data.data_root}/resized_hypersim',
      aug_crop=2, resolution=(224, 224), transform=SeqColorJitter, num_views=${data.num_views},
      n_corres=0, samples_per_scene=1)
    - BlendedMVS_Multi(allow_repeat=False, split='train', ROOT='${data.data_root}/blendedMVS/blendedMVS',
      aug_crop=2, resolution=224, transform=SeqColorJitter, num_views=${data.num_views},
      n_corres=0, samples_per_scene=1)
    - BlendedMVS_Multi(allow_repeat=False, split='train', ROOT='${data.data_root}/blendedMVS/blendedMVSpp',
      aug_crop=2, resolution=224, transform=SeqColorJitter, num_views=${data.num_views},
      n_corres=0, samples_per_scene=1)
    - ScanNetpp_Multi(allow_repeat=False, split='train', ROOT='${data.data_root}/scannetpp_depth/full',
      aug_crop=2, resolution=224, transform=SeqColorJitter, num_views=${data.num_views},
      n_corres=0, samples_per_scene=1)
    - ScanNetpp_Multi(allow_repeat=False, split='train', ROOT='${data.data_root}/scannetpp_depth/nomask',
      aug_crop=2, resolution=224, transform=SeqColorJitter, num_views=${data.num_views},
      n_corres=0, samples_per_scene=1)
    validation_datasets:
    - HyperSim_Multi(allow_repeat=False, split='test', ROOT='${data.data_root}/resized_hypersim',
      resolution=224, num_views=${data.num_views_val}, seed=777, samples_per_scene=1)
    - Infinigen_Multi(allow_repeat=False, split='train', ROOT='${data.data_root}/infinigen',
      resolution=224, num_views=${data.num_views}, seed=777, samples_per_scene=1)
    test_datasets:
    - HyperSim_Multi(allow_repeat=False, split='test', ROOT='${data.data_root}/resized_hypersim',
      resolution=224, num_views=${data.num_views_val}, seed=777, samples_per_scene=1)
    - SevenScenes_Multi(allow_repeat=False, split='train', ROOT='${data.data_root}/7scenes',
      resolution=224, num_views=${data.num_views}, seed=777, samples_per_scene=1)
    - Infinigen_Multi(allow_repeat=False, split='train', ROOT='${data.data_root}/infinigen',
      resolution=224, num_views=${data.num_views}, seed=777, samples_per_scene=1)
    batch_size_per_device: 12
    batch_size_per_device_val: 12
    batch_size_per_device_test: 12
    num_workers: 2
    num_workers_val: 2
    num_workers_test: 2
    pin_memory: false
    persistent_workers: false
    seed: 666
model:
  _target_: fast3r.models.multiview_dust3r_module.MultiViewDUSt3RLitModule
  # pretrained: /lc/code/pretrained/vggt/weights/model.pt_vggtdino
  pretrained: /lc/code/pretrained/depth_anything/depth_anything_vitl14.pt_depthanything
  log_detail: false
  weight_decay: 0.05
  layer_decay: 1.0
  scale_keywords:
  - encoder
  - decoder
  - downstream_head
  lr_scales:
  - 0.001
  - 1.0
  - 1.0
  eval_use_pts3d_from_local_head: true
  compile: false
  optimizer:
    _target_: torch.optim.AdamW
    _partial_: true
    betas:
    - 0.9
    - 0.95
    weight_decay: 0.05
  scheduler:
    warmup_epochs: 10
    epochs: ${trainer.max_epochs}
    eta_min: 1.0e-07
    min_lr: 1.0e-06
    lr: 5.0e-05
  net:
    _target_: fast3r.models.fast3r.Fast3R
    freeze: encoder
    encoder_args:
      encoder_type: dino_v2
      img_size: 512
      patch_size: 14
      patch_embed_cls: PatchEmbedDust3R
      embed_dim: 1024
      num_register_tokens: 0 #for depth anything is 0, vggt is 4
      num_heads: 16
      depth: 24
      mlp_ratio: 4
      pos_embed: RoPE100
      attn_implementation: flash_attention
    decoder_args:
      decoder_type: fast3r
      attn_bias_for_inference_enabled: false
      random_image_idx_embedding: true
      enc_embed_dim: ${model.net.encoder_args.embed_dim}
      embed_dim: 1024
      num_heads: 16
      depth: 24
      mlp_ratio: 4.0
      qkv_bias: true
      drop: 0.0
      attn_drop: 0.0
      attn_implementation: flash_attention
    head_args:
      head_type: dpt
      output_mode: pts3d
      landscape_only: false
      with_local_head: true
      depth_mode:
      - exp
      - -.inf
      - .inf
      conf_mode:
      - exp
      - 1
      - .inf
      pose_mode:
      - exp
      - -.inf
      - .inf
      patch_size: 16
      has_pose: true
      has_rgb: false
      has_cam: true
      cam_dim: 6
  train_criterion:
    _target_: fast3r.dust3r.losses.ConfLossMultiviewPose
    pixel_loss:
      _target_: fast3r.dust3r.losses.Regr3DMultiviewV3
      criterion:
        _target_: fast3r.dust3r.losses.L21Loss
      norm_mode: avg_dis
    alpha: 0.2
    pose_loss:
      _target_: fast3r.dust3r.loss.pose_loss.CameraPoseLoss
      weight: 1.0
    cam_loss:
      _target_: fast3r.dust3r.loss.pose_loss.CameraIntrinsicLoss
      weight: 1.0
  validation_criterion:
    _target_: fast3r.dust3r.losses.ConfLossMultiviewPose
    pixel_loss:
      _target_: fast3r.dust3r.losses.Regr3DMultiviewV3
      criterion:
        _target_: fast3r.dust3r.losses.L21Loss
      norm_mode: avg_dis
    alpha: 0.2
    pose_loss:
      _target_: fast3r.dust3r.loss.pose_loss.CameraPoseLoss
      weight: 1.0
    cam_loss:
      _target_: fast3r.dust3r.loss.pose_loss.CameraIntrinsicLoss
      weight: 0.5
callbacks:
  memory_cleanup:
    _target_: fast3r.models.callbacks.memory_cleanup.MemoryCleanupCallback
  early_stopping:
    _target_: pytorch_lightning.callbacks.EarlyStopping
    monitor: val/loss
    min_delta: 0.0
    patience: 15
    verbose: false
    mode: min
    strict: true
    check_finite: true
    stopping_threshold: null
    divergence_threshold: null
    check_on_train_epoch_end: null
  rich_progress_bar:
    _target_: pytorch_lightning.callbacks.progress.rich_progress.RichProgressBar
    refresh_rate: 1
    leave: false
    theme:
      _target_: pytorch_lightning.callbacks.progress.rich_progress.RichProgressBarTheme
      description: green_yellow
      progress_bar: green1
      progress_bar_finished: green1
      progress_bar_pulse: '#6206E0'
      batch_progress: green_yellow
      time: blue
      processing_speed: cyan
      metrics: grey82
      metrics_text_delimiter: ' '
      metrics_format: .4g
  model_checkpoint:
    dirpath: ${paths.output_dir}/checkpoints
    filename: epoch_{epoch:03d}
    monitor: val/loss
    mode: min
    save_last: false
    auto_insert_metric_name: false
    save_weights_only: true
    every_n_epochs: 1
  model_summary:
    max_depth: -1
logger:
  csv:
    _target_: pytorch_lightning.loggers.csv_logs.CSVLogger
    save_dir: ${paths.output_dir}
    name: csv/
    prefix: ''
    version: ''
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  _convert_: partial
  default_root_dir: ${paths.output_dir}
  min_epochs: 0
  max_epochs: 120
  accelerator: gpu
  devices: 1
  precision: bf16-mixed
  check_val_every_n_epoch: 1
  enable_model_summary: false
  num_sanity_val_steps: 0
  deterministic: false
paths:
  root_dir: ${oc.env:PROJECT_ROOT}
  data_dir: ${paths.root_dir}/data/
  log_dir: ${paths.root_dir}/dlogs/
  output_dir: ${hydra:runtime.output_dir}
  work_dir: ${hydra:runtime.cwd}
  run_folder_name: ${now:%Y-%m-%d}_${now:%H-%M-%S}
extras:
  ignore_warnings: false
  enforce_tags: true
  print_config: true
